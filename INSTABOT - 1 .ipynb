{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de801cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# IMPORTING NECESSARY LIBRARIES AND THEIR UTILITIES\n",
    "# -------------------------------------------------\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys # provide keys in the keyboard like RETURN, F1, ALT\n",
    "from selenium.webdriver.support.ui import Select # to select the option html attribute\n",
    "from selenium.webdriver.support.ui import WebDriverWait # To use implcit and explicit wait\n",
    "from selenium.webdriver.support import expected_conditions as EC  # use in explicitly wait\n",
    "from selenium.webdriver.common.by import By   # to select the attribute by Class,link_text\n",
    "from selenium import webdriver  # import web Driver\n",
    "import time  # it use in wait\n",
    "from bs4 import BeautifulSoup # work with attributes \n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621857bf",
   "metadata": {},
   "source": [
    "### 1) Login to your Instagram Handle\n",
    "#### 1.1) Submit with sample username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d931e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox() # saved ' gecko ' in the same file folder\n",
    "driver.get(\"https://www.instagram.com/\") # passing instagram link \n",
    "wait = WebDriverWait(driver , 10) # wait for 15 secs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c40468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding input fields\n",
    "wait = WebDriverWait(driver , 5)\n",
    "u_name = driver.find_element_by_name(\"username\") # finding input fields by name ' username '\n",
    "password = driver.find_element_by_name(\"password\") # finding input fields by name ' password '\n",
    "\n",
    "# entering credentials \n",
    "u_name.send_keys(\"instabotcn\")  \n",
    "password.send_keys('06shishe11')\n",
    " # wait for 5 secs before logging in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b05f2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show\n",
      "Log In\n",
      "Log in with Facebook\n"
     ]
    }
   ],
   "source": [
    "# fetching all button type elements and finding which one is ' Log In ' \n",
    "login = driver.find_elements_by_tag_name(\"button\")\n",
    "for el in login:\n",
    "    print(el.text)\n",
    "log = login[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d111663",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait( driver , 10 ) # wait for 10 secs before clicking \n",
    "\n",
    "# confirmation alert is popped asking to save login information ... we click ' Not Now '\n",
    "decline = driver.find_element_by_class_name('cmbtv') # div class of not now \n",
    "decline.click()\n",
    "wait = WebDriverWait( driver , 10 ) # wait for 10 secs before clicking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfae5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Logged In !!!\n"
     ]
    }
   ],
   "source": [
    "# Notification alert asked ... we click ' Not Now '\n",
    "decline_noti = driver.find_element_by_xpath('//div[@class = \"mt3GC\"]//button[2]') # div class of not now \n",
    "decline_noti.click()\n",
    "print(\"Successfully Logged In !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46a4c4",
   "metadata": {},
   "source": [
    "### 2) Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”\n",
    "#### 2.1) Note : Make sure to avoid printing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6dd9a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodtalkindia\n",
      "foodieveggie\n",
      "vibrantshades009\n",
      "foodzeee\n",
      "food_bragger\n",
      "foodfeastfiesta\n",
      "food\n",
      "foodexcursionist90\n",
      "thefoodtalks_\n",
      "foodiesoul08\n",
      "food_belly11\n",
      "itsacheezylife\n",
      "food_travel_etc\n",
      "foodiesdelhite\n",
      "foodiesince96\n",
      "foodcomics_\n",
      "foodmaniacindia\n",
      "foodlust_delhi\n",
      "food_gambler\n",
      "foodbloggersingh\n",
      "food_glued\n",
      "foodinveins\n",
      "food_lunatic\n",
      "foodie_incarnate\n",
      "itisthematteroftaste\n",
      "foodlamour\n",
      "my_foodravel\n",
      "foody_kshitij\n",
      "dfim\n",
      "foodindelhibelly\n",
      "halal_food_drooler\n",
      "foodad_mirer\n",
      "food_fusions_\n",
      "foodflashindia\n",
      "foodofgoa\n",
      "foodiesparsh\n",
      "yourfoodlab\n",
      "foodywoodyme\n",
      "food_wackadoos\n",
      "foodie_vakil\n",
      "thegourmet_traveller\n",
      "foodiearuna\n",
      "food_bunny98\n",
      "foodie_anshul\n",
      "food_in_my_vein\n",
      "thelalitftc\n",
      "food.over.curve\n",
      "foodieforeverandever23\n",
      "foodiee00\n",
      "mytravelbite\n",
      "shreo_s_food_diary\n",
      "foodelhi\n"
     ]
    }
   ],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.send_keys('food') # passing food\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handles = driver.find_elements_by_xpath('//a[@class = \"-qQT3\"]') # fetching top food list handles \n",
    "\n",
    "food_list = []  # making a list that holds names\n",
    "for i in handles:\n",
    "    if 'explore' in i.get_attribute('href'): # if explore present in link then it is a hashtag\n",
    "        continue\n",
    "    else:       \n",
    "        s = i.get_attribute('href').split('/') # https://www.instagram.com/foodtalkindia\n",
    "        print(s[3]) # after split s = ['https:','','www.instagram.com','foodtalkindia']\n",
    "        food_list.append(s[3])   # appending s[3] in food_list  \n",
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search input box again for further questions \n",
    "a.clear() # clear box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c283779",
   "metadata": {},
   "source": [
    "### 3) Searching and Opening a profile using \n",
    "#### Open profile of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fb688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCHED AND OPENED 'So Delhi' INSTAGRAM PAGE !!!\n"
     ]
    }
   ],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.send_keys('So Delhi') # passing So Delhi \n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is So Delhi hence searching by class\n",
    "handle.click() # opening the profile \n",
    "print(\"SEARCHED AND OPENED 'So Delhi' INSTAGRAM PAGE !!!\")\n",
    "time.sleep(3) # stays on the page for 3 secs\n",
    "driver.back() # getting back to main page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d8ee6",
   "metadata": {},
   "source": [
    "### 4) Follow/Unfollow given handle - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768598b",
   "metadata": {},
   "source": [
    "#### 4.1) Open the Instagram Handle of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22549bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENED 'So Delhi' INSTAGRAM PAGE !!!\n"
     ]
    }
   ],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.clear()\n",
    "a.send_keys('So Delhi') # passing So Delhi \n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is So Delhi hence searching by class\n",
    "handle.click() # opening the profile \n",
    "print(\"OPENED 'So Delhi' INSTAGRAM PAGE !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13937c",
   "metadata": {},
   "source": [
    "#### 4.2) Start following it. Print a message if you are already following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00249fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALREADY FOLLOWING !!!\n"
     ]
    }
   ],
   "source": [
    "follow_btn = driver.find_element_by_class_name(\"_6VtSN\") # fetching ' follow ' button with class \n",
    "if 'Following' in follow_btn.get_attribute(\"innerHTML\"): # checking if already following \n",
    "    print(\"ALREADY FOLLOWING !!!\")\n",
    "else:\n",
    "    follow_btn.click() # clicking to follow\n",
    "    print(\"STARTED FOLLOWING NOW !!!\") # printing acknowledgement of following \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052388d",
   "metadata": {},
   "source": [
    "#### 4.3) After following, unfollow the instagram handle. Print a message if you have already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84d8ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNFOLLOWED 'So Delhi' PAGE FROM INSTAGRAM !!!\n"
     ]
    }
   ],
   "source": [
    "if follow_btn.text == 'Follow':\n",
    "    print(\"ALREADY UNFOLLOWED 'So Delhi' INSTAGRAM PAGE !!!\")\n",
    "else:\n",
    "    follow_btn.click() # clicking the follow button so that we can unfollow the account \n",
    "    time.sleep(4) # wait for 4 secs before unfollowing\n",
    "\n",
    "    unfollow_btn = driver.find_element_by_class_name(\"-Cab_\") # confirmation alert is popped\n",
    "    unfollow_btn.click() # unfollowed the page \n",
    "    print(\"UNFOLLOWED 'So Delhi' PAGE FROM INSTAGRAM !!!\") # aknowledging unfollowing by printing this message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a90c7",
   "metadata": {},
   "source": [
    "### 5) Like/Unlike posts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251264f",
   "metadata": {},
   "source": [
    "#### 5.1) Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f6938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()  # back to homepage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bab30fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Liked Post No.: 1\n",
      "Already Liked Post No.: 2\n",
      "Already Liked Post No.: 3\n",
      "Already Liked Post No.: 4\n",
      "Already Liked Post No.: 5\n",
      "Already Liked Post No.: 6\n",
      "Already Liked Post No.: 7\n",
      "Already Liked Post No.: 8\n",
      "Already Liked Post No.: 9\n",
      "Already Liked Post No.: 10\n",
      "Already Liked Post No.: 11\n",
      "Already Liked Post No.: 12\n",
      "Already Liked Post No.: 13\n",
      "Already Liked Post No.: 14\n",
      "Already Liked Post No.: 15\n",
      "Already Liked Post No.: 16\n",
      "Already Liked Post No.: 17\n",
      "Already Liked Post No.: 18\n",
      "Already Liked Post No.: 19\n",
      "Already Liked Post No.: 20\n",
      "Liked Post No.: 21\n",
      "Liked Post No.: 22\n",
      "Liked Post No.: 23\n",
      "Liked Post No.: 24\n",
      "Liked Post No.: 25\n",
      "Liked Post No.: 26\n",
      "Liked Post No.: 27\n",
      "Liked Post No.: 28\n",
      "Liked Post No.: 29\n",
      "Liked Post No.: 30\n"
     ]
    }
   ],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.send_keys('dilsefoodie') # passing 'dilsefoodie'\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is dilsefoodie hence searching by class\n",
    "handle.click() # opening the profile \n",
    "time.sleep(3)\n",
    "count = 1 # initiating post counter\n",
    "                        \n",
    "post = driver.find_elements_by_xpath('//div[contains(@class,\"v1Nh3\")]') # finding post with class\n",
    "\n",
    "for i in post: # iterating over posts\n",
    "    if count == 31: # check if 30 posts are done then break from loop\n",
    "        break \n",
    "\n",
    "    i.click() # click on each post\n",
    "    time.sleep(3) # time to load the data \n",
    "    like_btn = driver.find_element_by_xpath(\"//span[@class='fr66n']\") # fetching the like button\n",
    "\n",
    "    data = like_btn.get_attribute(\"innerHTML\") # getting all the data using innerHTML , \n",
    "    # xpath was not working properly thats why used this approach\n",
    "    \n",
    "    if 'Like' in data: # check condition for liked posts\n",
    "        like_btn.click() # like the post\n",
    "        print(\"Liked Post No.:\" , count) # acknowledging the change by printing success message\n",
    "    else:\n",
    "        print(\"Already Liked Post No.:\" , count) # if already liked \n",
    "\n",
    "    close_btn = wait.until(EC.presence_of_element_located((By.XPATH,'//div[contains(@class,\"TxciK\")]/button')))\n",
    "    # post close button\n",
    "\n",
    "    close_btn.click() # clicking on close button\n",
    "    count += 1  # counting posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9396d18",
   "metadata": {},
   "source": [
    "#### 5.2) Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc70ad87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unliked Post No.: 1\n",
      "Unliked Post No.: 2\n",
      "Unliked Post No.: 3\n",
      "Unliked Post No.: 4\n",
      "Unliked Post No.: 5\n",
      "Unliked Post No.: 6\n",
      "Unliked Post No.: 7\n",
      "Unliked Post No.: 8\n",
      "Unliked Post No.: 9\n",
      "Unliked Post No.: 10\n",
      "Unliked Post No.: 11\n",
      "Unliked Post No.: 12\n",
      "Unliked Post No.: 13\n",
      "Unliked Post No.: 14\n",
      "Unliked Post No.: 15\n",
      "Unliked Post No.: 16\n",
      "Unliked Post No.: 17\n",
      "Unliked Post No.: 18\n",
      "Unliked Post No.: 19\n",
      "Unliked Post No.: 20\n",
      "Unliked Post No.: 21\n",
      "Unliked Post No.: 22\n",
      "Unliked Post No.: 23\n",
      "Unliked Post No.: 24\n",
      "Unliked Post No.: 25\n",
      "Unliked Post No.: 26\n",
      "Unliked Post No.: 27\n",
      "Unliked Post No.: 28\n",
      "Unliked Post No.: 29\n",
      "Unliked Post No.: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 1 # to count no. of posts\n",
    "\n",
    "post = driver.find_elements_by_xpath('//div[contains(@class,\"v1Nh3\")]') # finding post with class\n",
    "\n",
    "for i in post: # iterating over posts\n",
    "    if count == 31: # check if 30 posts are done then break from loop\n",
    "        break \n",
    "    i.click() # click on each post\n",
    "    time.sleep(3) # time to load the data \n",
    "    like_btn = driver.find_element_by_xpath(\"//span[@class='fr66n']\") # fetching the like button\n",
    "\n",
    "    data = like_btn.get_attribute(\"innerHTML\") # getting all the data using innerHTML , \n",
    "    # xpath was not working properly thats why used this approach\n",
    "    \n",
    "    if 'Unlike' in data: # check condition for liked posts\n",
    "        like_btn.click() # like the post\n",
    "        print(\"Unliked Post No.:\" , count) # acknowledging the change by printing success message\n",
    "    else:\n",
    "        print(\"Already Unliked Post No.:\" , count) # if already liked \n",
    "\n",
    "    close_btn = wait.until(EC.presence_of_element_located((By.XPATH,'//div[contains(@class,\"TxciK\")]/button')))\n",
    "    # post close button\n",
    "\n",
    "    close_btn.click() # clicking on close button\n",
    "    count += 1  # counting posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335008a",
   "metadata": {},
   "source": [
    "### 6)  Extract list of followers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c3c41",
   "metadata": {},
   "source": [
    "#### 6.1) Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22229664",
   "metadata": {},
   "source": [
    "### --------------------------------- \n",
    "### FOODTALKINDIA \n",
    "### --------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "729bbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.clear()\n",
    "a.send_keys('foodtalkindia') # passing 'dilsefoodie'\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is dilsefoodie hence searching by class\n",
    "handle.click() # opening the profile \n",
    "time.sleep(2)\n",
    "followers_button = wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"-nal3\")]'))) #follower button search\n",
    "followers_button.click()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ced5998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shubho_chakravarty\n",
      "abhijeet_multani\n",
      "nrupa_beyondtheplate\n",
      "kirangandhi_bulbul\n",
      "un_kahealfaaz\n",
      "seemajain318\n",
      "dimpi.gehlot\n",
      "monilnegi\n",
      "mohitgouda\n",
      "wataburgerguwahati\n",
      "jinkomaniac\n",
      "kunal_trading_shop\n",
      "rd0091\n",
      "hanish.bhatt\n",
      "bowlbala\n",
      "recipes_with_rasika\n",
      "bboxrun\n",
      "delites_foods\n",
      "devendradas75\n",
      "kitchenofflavours\n",
      "barani.ramakrishnan\n",
      "sarabsingh100\n",
      "kalpana65dubey\n",
      "1233girly\n",
      "__.anuuuuuu\n",
      "anki__0925\n",
      "rajnikanth815\n",
      "astrologer_kabir_khan\n",
      "msaifq\n",
      "_rachit.shrivastava_\n",
      "iamavvybrarofficial\n",
      "sonam_3050\n",
      "brimfulofananda\n",
      "sap_saan\n",
      "kam2308\n",
      "sh.ruti1569\n",
      "_with_creative_mind_\n",
      "ashshaishrma\n",
      "sonttkkeshivaajii\n",
      "saprabarchana\n",
      "ravibhushan290\n",
      "veeveemon\n",
      "shalini._kurmi\n",
      "thefoodcanvas_\n",
      "aashvi_s\n",
      "divya_rawat222\n",
      "food_love734\n",
      "raj_pratapsingh123\n",
      "poetryfoodart\n",
      "dhiren__81\n",
      "saav196\n",
      "sammaduramthomas\n",
      "vinsazkitchen\n",
      "kri_dha06\n",
      "yourcookingdentist\n",
      "iamraidas\n",
      "just_ruined\n",
      "ajjinx7\n",
      "healththeline\n",
      "shahin_shah_kanichirakkal\n",
      "vrusha_dessai\n",
      "wadhwanidhi26\n",
      "__foody_foreverrr\n",
      "royal_v.b_134\n",
      "jairanaa\n",
      "delhifood91\n",
      "leena.sejpal.14\n",
      "vedantshahare_07\n",
      "sachin_____rathod\n",
      "unchartedmusings\n",
      "puneeth_gowda\n",
      "caketime_2019\n",
      "iakashvats\n",
      "chinmaya_chinu_\n",
      "mohor243\n",
      "sukh_deep226\n",
      "p_i_y_u__sh143\n",
      "rezzing9\n",
      "_imshubhi_\n",
      "stylme70\n",
      "choc.olate9175\n",
      "syed_rizzu\n",
      "lakshaypandit_999\n",
      "dularizala\n",
      "bbeautiful_58\n",
      "aadil14350\n",
      "shivam.verma2\n",
      "official.auxilian\n",
      "hoggersmaps_goan\n",
      "iam_yodhin.bali\n",
      "happyness_quotes18\n",
      "norbertportka\n",
      "not_so_mango_vijeta\n",
      "hungry_birds_restaurant\n",
      "tigarcrick\n",
      "srot.the.source\n",
      "kurochia52\n",
      "mohtarmamehra\n",
      "patharkar_vidhi\n",
      "chefenamulla\n",
      "taherafata18\n",
      "neenugupta48\n",
      "apurva0916\n",
      "chotisishayar\n",
      "deekshadiwan\n",
      "apoorvatiwaritiwari\n",
      "parv4466\n",
      "tabassumsarafaraj\n",
      "chawlarenuchawla\n",
      "daawat_e_junoon\n",
      "mdnyt_cravings\n",
      "4336.khushi\n",
      "cookingtales_352\n",
      "positive___.vibes__\n",
      "raj_khan_official09\n",
      "mimopolitan\n",
      "like_a_captain1\n",
      "stewart.ofc.25\n",
      "deep.in.the.sand\n",
      "certifiedbawarchi\n",
      "smr_8715\n",
      "imouniro__y\n",
      "ankita.modi.ca\n",
      "cocoportindia\n",
      "vickyghodke1\n",
      "__sarah_wu__\n",
      "foodies.farm\n",
      "japneet.kaur.bajwa\n",
      "harshitasharma021\n",
      "foodsveda9\n",
      "rathi3860\n",
      "uttam.bera.129\n",
      "byjeffcarrel\n",
      "seedkitchen.restaurant\n",
      "neethu_m_11\n",
      "shikhartiwari_19\n",
      "shreerathnamjailroaddelhi\n",
      "askgarima\n",
      "thedefiners\n",
      "anandpurva\n",
      "golu345m\n",
      "k_i_r_a_0.7\n",
      "vora.kaushik_09\n",
      "ankush_yadav_amethi7100\n",
      "escape.wid.me\n",
      "arfaathussain8100\n",
      "maitrishah2104\n",
      "its_pallavig98\n",
      "_shalinisingh_._\n",
      "daily_veg_recipes\n",
      "_.meals_appeals._\n",
      "salonisinha__\n",
      "experiencessoul_\n",
      "_kanikananda\n",
      "she_cook_n_click\n",
      "priya.raperia\n",
      "yogi_gautam_\n",
      "soyaummfoodproducts\n",
      "preetiijha\n",
      "seema_dhanuk_\n",
      "deeksha.0808\n",
      "nani_ki_recipe_\n",
      "chaudhry.jaya\n",
      "nanhu_uttam\n",
      "kaahramann0\n",
      "chefconnectindia\n",
      "harsingh6549\n",
      "bhishmafoods\n",
      "sarika_bodhe\n",
      "durgeshnkr\n",
      "punyajasingh10\n",
      "chitra_bharti_events_anta\n",
      "jaan_cookhouse17\n",
      "style.that.curve\n",
      "manishmehra56\n",
      "m_o_n_t_y7343\n",
      "burman_meenakshi02\n",
      "jerryadavoo7\n",
      "devikakohli\n",
      "sanjayakumar179\n",
      "srk_srk_official\n",
      "food14cp\n",
      "jk786.rohit\n",
      "ieltsdestination\n",
      "suryanshg01\n",
      "virajmodi2212\n",
      "juicewrld_og\n",
      "_ss_photography_._\n",
      "s4sidhant\n",
      "colours_in_empty_rainbow\n",
      "tgb.isanpur\n",
      "rahul_nigam1531\n",
      "hello_hell_1989\n",
      "adventure.vlogger\n",
      "mahesh_sharma_1974__\n",
      "psycho_somu\n",
      "chef_d_07\n",
      "singing.again\n",
      "dipikasahamukherjee\n",
      "sudheeramya007\n",
      "get_early\n",
      "pramodavacharofficial\n",
      "dharmesh_dh12\n",
      "swaad_yummy_tummy\n",
      "srth_10\n",
      "jrdkcookingdiaries\n",
      "amir_khanoffi\n",
      "vedansh_vasani_1007\n",
      "foodie.photography2021\n",
      "kriti196\n",
      "wineanddinemd\n",
      "the_actual_siddharathsehdev\n",
      "_fionalobo_\n",
      "thehealthfactor_silpi\n",
      "ridhicooks\n",
      "kabirrahman9\n",
      "thesavouryspoon\n",
      "rakkshet\n",
      "monasaxena28\n",
      "prernaluthraaaa\n",
      "tarun_inder_kaur\n",
      "lilly_kxlx\n",
      "inspiring.optimism\n",
      "sharim_saif_992\n",
      "kochhartanvi\n",
      "taalifoods.in\n",
      "greenmantra2020\n",
      "gari_foodaholic\n",
      "smart_wish009\n",
      "worlds_beautiful_girls_\n",
      "thelajawaab\n",
      "neha1987\n",
      "yashikasinghall\n",
      "julieallaboutfood\n",
      "premiere_kitchens\n",
      "srishtimirandian\n",
      "shadesoflovelyfood\n",
      "not_a_baker_shh\n",
      "pavantagare\n",
      "gangradeanju\n",
      "jayesh_rohira\n",
      "iamtrending__\n",
      "sanoop__saj\n",
      "mhetre_nikky_143\n",
      "shivifamily\n",
      "_p_r_a_n_j_a_l2\n",
      "shubhamsharma5894\n",
      "osmankhan682\n",
      "foodie_shoodi\n",
      "muthaliifrasheek\n",
      "einaahluwalia\n",
      "nishant_patel_007_\n",
      "anchorfoodprofessionalsindia\n",
      "soniasekh\n",
      "jeremiah_jerema\n",
      "_ram6969\n",
      "govindr_sen\n",
      "sheratonhyderabad\n",
      "umeer.md\n",
      "thefoodievlog\n",
      "dhruvienterprises_cafedesire\n",
      "harpreet__72\n",
      "cookingabroadig\n",
      "bong_foodie2021\n",
      "jhabindarj.c\n",
      "myfood_flavours\n",
      "virmani99\n",
      "meenakukreja1506\n",
      "aruns_as\n",
      "online_shop_p__\n",
      "nice_joke_bro\n",
      "onestepfor_fitness\n",
      "new_tmkoc_\n",
      "sai_chintu_564\n",
      "deogadeshubham\n",
      "dontfindme00\n",
      "uncertainlyweird\n",
      "amil__d_x_\n",
      "__a_l_o_n_e_4_4_4\n",
      "ritu.aryakukreja\n",
      "hlmahanthesh\n",
      "deliciousfoodfusion\n",
      "_the_.food_.icon_\n",
      "k.m.imrankhan4\n",
      "jonna_vijaya\n",
      "dhruv_sony_\n",
      "splender__mekhma\n",
      "ashwinikushalnagar\n",
      "the_plateproject\n",
      "wha.ahw\n",
      "pverma27\n",
      "rainbowcolours.paints\n",
      "arpan1164\n",
      "saylichavan23\n",
      "pkarmatik\n",
      "gur.noor2108\n",
      "tara_sroa\n",
      "theneerajrathour\n",
      "foods121212\n",
      "khushayy2\n",
      "foodzonal\n",
      "tipuvyas666\n",
      "up__kitchen\n",
      "mulla.inam\n",
      "sachi_hongal\n",
      "sunil_variety_kulfi\n",
      "855746uufgyg\n",
      "sumanjali_21\n",
      "mahakal_clb\n",
      "lavanya.17._\n",
      "esh.0612\n",
      "bhook_lagi_hain\n",
      "villotale\n",
      "nishaa5055\n",
      "i_am_human_only_\n",
      "foody_varshap\n",
      "gauriicegauriice\n",
      "shanmugapriya2743\n",
      "the_blessed_bowl\n",
      "drewjoosamu\n",
      "sharatswamy\n",
      "up_16_0007\n",
      "sandeep.ray.986\n",
      "paradkarpallavi\n",
      "iam_deepak_manchanda\n",
      "photopedia_2.0_\n",
      "ameenu7252\n",
      "chefmansi\n",
      "masala_foodies\n",
      "lovely_maria74\n",
      "jeswincreations\n",
      "mountain_mastiff\n",
      "food_plate__\n",
      "abhi.king302\n",
      "kavitadube71\n",
      "ramyakrishnan666\n",
      "sainishrishti\n",
      "abhis.kitchen.01\n",
      "vidhunvasavan\n",
      "eats__and__treat\n",
      "sahiljaglan665\n",
      "dt.pearson\n",
      "miss_foodalicious_\n",
      "limitbreaker_123\n",
      "food_and_drinks_and_travel\n",
      "kumar.reena28\n",
      "_search_discover\n",
      "nalini_anjna\n",
      "pb.sareen\n",
      "akshay_mittal_18\n",
      "i_value_people\n",
      "aishwarya.suja\n",
      "foodographybyvipin\n",
      "soul_shalu_07\n",
      "yasdhani_cr7\n",
      "post_caffeinated\n",
      "thefoodieblogs\n",
      "jnvaibhav\n",
      "soul_chowpatti\n",
      "iankitbalodi\n",
      "the.saravanans\n",
      "anamtahmad\n",
      "anshul_wild\n",
      "nematnama\n",
      "__diya____14\n",
      "only_for_food9\n",
      "priti_choraria\n",
      "swetadhm\n",
      "pabitra.varietybox\n",
      "_ab_engineering_\n",
      "jimmy_sb09\n",
      "leela_mrs\n",
      "prem_tiwariii\n",
      "gorakhpurgram\n",
      "thefanaticalcook\n",
      "poonamlila\n",
      "rahulstadkaa\n",
      "black666403\n",
      "_petuk_18_\n",
      "lambag2020\n",
      "foodbymaabeti\n",
      "manisha6287\n",
      "faisalasrr\n",
      "unlasting_ink\n",
      "ankushkapoor18\n",
      "hahhahahawjajkkaklal\n",
      "deeksha_r_naidu_\n",
      "feedfantasy3\n",
      "k3033494\n",
      "khushpreetkaurbadesha\n",
      "sheikhfatima___\n",
      "prabhleenkaurmanku\n",
      "mayuri026\n",
      "raj_chat\n",
      "spanishwithmansi\n",
      "you__zeeyan\n",
      "pardeepranga17\n",
      "dhanraj619r\n",
      "blacklover055\n",
      "srujanagv23\n",
      "prajapati_tarang94\n",
      "_chittor_garh\n",
      "sumankabagheecha\n",
      "nandinimittal\n",
      "pratham_dev12\n",
      "kattajn30\n",
      "suhanakatadka\n",
      "trintrinmrin\n",
      "__bullet_loverz\n",
      "food_l0ver._\n",
      "foodlover6029\n",
      "repost.wala.page\n",
      "arjunreddy665\n",
      "jd_pvt.ltd\n",
      "nehahassan1608\n",
      "pimpnlay\n",
      "2301rr\n",
      "drteeth.co\n",
      "as_sudhakar.co\n",
      "upscdream23\n",
      "___saumya12___\n",
      "avlent_06\n",
      "mohit.rathour_240\n",
      "sagar_kumar_rajput_saab\n",
      "savio_camara\n",
      "jagmohanbuttar\n",
      "kongu.s.14\n",
      "prajot.rajput\n",
      "saipranjpe\n",
      "chef.mhelbien\n",
      "dev_bhai_0000\n",
      "good_idea.26\n",
      "ria_guptaa_\n",
      "pavan_7368\n",
      "spoonofspices_\n",
      "ashish_yadav_sher\n",
      "maakihaathse\n",
      "s_farah_collection\n",
      "khanshekhu_054\n",
      "sargamsardana\n",
      "raajeev.pvt\n",
      "karthiga_ravikumar\n",
      "samkhanfc1\n",
      "thakur_villa_panchgani\n",
      "marionbonneaux\n",
      "eatwithnishi\n",
      "foodietroll04\n",
      "mann_kitchen\n",
      "021beyou\n",
      "ravijore28\n",
      "eatroadyt\n",
      "chikuverma99\n",
      "panchi662021\n",
      "exploremarketsofdelhi\n",
      "dattboiii.d\n",
      "foodtech_network\n",
      "meghagoyal1711\n",
      "preetsunam69\n",
      "officiallucknowkirasoi\n",
      "ekta23584\n",
      "shwetaalways\n",
      "swatigupta000\n",
      "aroma.of.food\n",
      "instagamer1144\n",
      "masoom_11920\n",
      "invinciblejha\n",
      "vilfin1234\n",
      "nikitaagoswami\n",
      "prashantsethi2\n",
      "vinod011297\n",
      "chardikla_online_foods_seller\n",
      "__hubabuba____\n",
      "vsmk.khan\n",
      "dpsahu3\n",
      "shivamrathore320\n",
      "vvenkatsp\n",
      "rajahuja28\n",
      "beand253\n",
      "bhupindersingla7222\n",
      "food_lovers.corner_2021\n",
      "goodfoodreceipes\n",
      "akhilnanda\n",
      "sankhe.manasvi\n",
      "sarthakpatel24__\n",
      "swatikarofficial\n",
      "shroffshanny\n",
      "serialcookersofficial\n",
      "reachneena\n",
      "keshav_kr91\n",
      "rishab_nomad_12\n",
      "yumiphuong6\n",
      "sagarsoni0705\n",
      "f_o_od_lovers\n",
      "travel_food_trekking\n",
      "rahulmarskole214466\n",
      "sunainigupta\n",
      "mohantysmitarani17\n",
      "snehal.singh__\n",
      "big.bite.food\n",
      "merabhartiyarasoi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flag = False # flag for condition\n",
    "while True: # check condition\n",
    "    b = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'isgrP'))) # wait till element is located\n",
    "    p = driver.find_element_by_class_name('isgrP')# search for followers\n",
    "    \n",
    "    p.click() # click on follower button                                                       \n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END) # moving end of document \n",
    "    if flag == False:\n",
    "        for i in range(6):\n",
    "            driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_UP)# to remove suggestion buttuon \n",
    "            time.sleep(1) \n",
    "        flag = True  # only work for one time\n",
    "    time.sleep(1)\n",
    "    p = driver.find_element_by_class_name('isgrP')# click on page of follower\n",
    "    follower_list = driver.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li')  #follower list\n",
    "    if len(follower_list) >= 500: # cheking for only 500 follower\n",
    "        break\n",
    "\n",
    "j = 0\n",
    "foodtalkindia_follower = [] # list of followers\n",
    "for i in follower_list:                                                                  \n",
    "    data = BeautifulSoup(i.get_attribute('innerHTML'),'html')  # retrieving data\n",
    "    follower_list = driver.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li')# follower list\n",
    "    if len(follower_list) >= 500: # check condition            \n",
    "        foodtalkindia_follower.append(data.a['href'].split('/')[1])# adding name in li\n",
    "        j+=1 # incrementing\n",
    "    if j==500: # only top 500 follower\n",
    "        break\n",
    "        \n",
    "for i in foodtalkindia_follower:\n",
    "    print(i) # printing names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3ac72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back() # back to main screen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69393900",
   "metadata": {},
   "source": [
    "### --------------------------------- \n",
    "### SO DELHI\n",
    "### --------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a280acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.clear()\n",
    "a.send_keys('sodelhi') # passing 'sodelhi'\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is dilsefoodie hence searching by class\n",
    "handle.click() # opening the profile \n",
    "time.sleep(2)\n",
    "followers_button = wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"-nal3\")]'))) #follower button search\n",
    "followers_button.click()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "123495c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nebhwaninaresh\n",
      "mummy_payal\n",
      "__healthy_bites\n",
      "tanyagupta1301_95\n",
      "achaljain94\n",
      "11_mohnish_11\n",
      "anirudhkrishnatreya\n",
      "rahul.dewra\n",
      "sapnakanjani\n",
      "thefunnyaddy\n",
      "himani.1209\n",
      "knot_lilly\n",
      "thatsochhavi\n",
      "alok__gupta_0502\n",
      "shagunmishra20\n",
      "themunchpage\n",
      "mishtymunchkin\n",
      "sh_ashi4466\n",
      "06_tanishka\n",
      "chiruhkm\n",
      "tomarutkarsh_0207\n",
      "spanishwithmansi\n",
      "dollar_thesmallpolar\n",
      "nickyypickyyy\n",
      "_agrima_sharma12\n",
      "bad_char\n",
      "zoo.bear._.alam\n",
      "1233girly\n",
      "deekshakaprii\n",
      "riya_bansal___\n",
      "kanishq_basoya_dellhii0001\n",
      "devgautam3806\n",
      "mannrajmander\n",
      "sushmitha0709\n",
      "_sha.shi__\n",
      "_anmolnagpal\n",
      "notawriterhere\n",
      "trippai.com_\n",
      "asmita_koli1122\n",
      "riya__7991\n",
      "shady_impact\n",
      "rajatbhallaofficial\n",
      "vilash4651\n",
      "_siddhantbhardwaj\n",
      "anjalirajput4026\n",
      "memes.4uh\n",
      "aditya._.manoj\n",
      "dennisss_24\n",
      "kolkataview\n",
      "nikhilsingh7403\n",
      "pratishtha19\n",
      "akanshadhingra_\n",
      "nandinijourno\n",
      "rac__1111\n",
      "dimpi.gehlot\n",
      "saamsara_19\n",
      "ninjastrawberryy\n",
      "enigma_the_mystery\n",
      "pandu_1972\n",
      "angel_chitranshi\n",
      "hupadhyay05\n",
      "kapil_dhanetwal\n",
      "kala.karr007\n",
      "aasthagupta.xx\n",
      "lazyhomi\n",
      "ashutoshsehrawat\n",
      "manjugupta1507\n",
      "archit__20\n",
      "the_chef__next_door\n",
      "duniyadari_ka_adda\n",
      "jatiin47\n",
      "yogendra_sastry\n",
      "adventuresbynicky\n",
      "rudiecockatoo\n",
      "seeemaskitchen\n",
      "nikithajain14683\n",
      "iamanishyadav\n",
      "banty_.15\n",
      "bhavesh.kumar91\n",
      "bliss.in.chaos\n",
      "shreen.behal\n",
      "mr_rizwan006\n",
      "prabvanikaur\n",
      "divya.zoylee\n",
      "karchiandkadai\n",
      "aditya.photo.s\n",
      "rhythmsingh23\n",
      "punjabizzofficial\n",
      "sylvanaesatpathy\n",
      "10pratik10\n",
      "ujjwalbhana\n",
      "mo7mmedkamal_\n",
      "officialabhi143\n",
      "sugarishsweety\n",
      "negi_vivek01\n",
      "thestech_29\n",
      "shivamm.verma\n",
      "aryaa_0396\n",
      "ra7vs\n",
      "lalit_5254\n",
      "officaldeeplambi.1\n",
      "maulshree.aggarwal\n",
      "yashii.12\n",
      "the.endless.jaunt\n",
      "happymalik_ind\n",
      "goswamichandana\n",
      "rishikikahani\n",
      "ded.ha_\n",
      "kr_santosh\n",
      "kashina_chadha\n",
      "ishantripathii\n",
      "ieyazsayeed\n",
      "eepseeta_parida\n",
      "eyeshot2k21\n",
      "byaan_m\n",
      "aanvijalan\n",
      "_nika._.j\n",
      "dhruvkapoor1\n",
      "shreyaa.jpg\n",
      "shreya.mahajan24\n",
      "bbeautiful_58\n",
      "mypersonalthoughts71\n",
      "lotusluxeexports\n",
      "kingofmixologist\n",
      "ankitbhardwaj0007\n",
      "raginivinaik\n",
      "ayushiiianand\n",
      "mathurjaini\n",
      "luv_the_peace\n",
      "nandi.smita\n",
      "arshadsabri\n",
      "pandat_axhixh_\n",
      "ritzigupta29\n",
      "anonymous__lam\n",
      "mohdkaif9958\n",
      "traveller1696\n",
      "purnimasharmaa_\n",
      "regards.aarya\n",
      "yashi_malhotra\n",
      "koh_inoor1\n",
      "_memes_bazar__\n",
      "itsdeepakkaintura\n",
      "poojagehlot___\n",
      "just.bgz\n",
      "munirquresh\n",
      "silent_screm\n",
      "thefeminaziiii\n",
      "rishirish\n",
      "anita.banerji\n",
      "juhi_bhoir\n",
      "beantbansal066\n",
      "saluja_nilu\n",
      "r.o.w.d.y__j.a.v.e.d\n",
      "fitoor_e_delhi\n",
      "manish.rathord.75\n",
      "demythifydelhi\n",
      "summercampingmalana\n",
      "srishtiverma29\n",
      "jitendra_mn1\n",
      "_sheena.bhatia_\n",
      "spamm_abitxx\n",
      "sharma16_m\n",
      "muskankunwar\n",
      "chiku2515\n",
      "hirdayaphotography_official\n",
      "evil.mon_ster\n",
      "reshmataneja9\n",
      "food48tadka\n",
      "krnmit04\n",
      "1212jayesh\n",
      "thesarjals\n",
      "nandinigarg35\n",
      "kadernana\n",
      "seedkitchen.restaurant\n",
      "niteshoshogt2019\n",
      "rakhisumal01\n",
      "patwaripradhyumna\n",
      "justsoolazyphotography\n",
      "kmurlimohan1\n",
      "bathrinath905\n",
      "amoll940\n",
      "bnchywellness\n",
      "smeettalaviya\n",
      "shreerathnamjailroaddelhi\n",
      "indu.bhutani.79\n",
      "vallecha\n",
      "_tannasometimes\n",
      "bhupendrabagla\n",
      "aadrrs_06\n",
      "ajay.dhawan.353\n",
      "simzpvtt\n",
      "amaanprit\n",
      "anoop.bhatia\n",
      "gun.rose.yyvv\n",
      "archisha_3108\n",
      "srishtig0204\n",
      "__sharma.rohit__\n",
      "pankaj_sikriwal1\n",
      "sumedhakataria\n",
      "saikumar.0081\n",
      "love_marriage_problem_703\n",
      "mr.shubhagarwal\n",
      "secret_soul_7\n",
      "_.ris_hika._\n",
      "kir_a_05\n",
      "_kanikananda\n",
      "jagiasunita\n",
      "strellerflower\n",
      "kamepriya1\n",
      "ksince_97\n",
      "_badal.choudhary_\n",
      "r_n_meghana\n",
      "ram_thesaviour\n",
      "purana_chai_wala\n",
      "iamanthaprerna\n",
      "this_is_garrry\n",
      "parass_____\n",
      "akarshisingh\n",
      "amit1.0\n",
      "manikumark4144\n",
      "parveengehl\n",
      "makeover_by_komal_garg\n",
      "priya_sharma0060\n",
      "pooja_yadav_96\n",
      "arushi.jain0406\n",
      "nishtz2005\n",
      "__uncanny____\n",
      "dhankhar_himanshi16\n",
      "manisha_4181\n",
      "aditimishra1228\n",
      "shadma_nazra786\n",
      "shankarramnr\n",
      "nandinichawla\n",
      "monassa.in\n",
      "harsha_kurup\n",
      "qudsiaanwar\n",
      "bhattreema\n",
      "aaminanoori\n",
      "girlbelongstohimalayas\n",
      "multip_lawed\n",
      "bibliophagist21\n",
      "vrundakhanolkar\n",
      "believe_love9\n",
      "reeta_sharma90\n",
      "ig_prashant\n",
      "guneet.kaur.28\n",
      "manishmehra56\n",
      "slices_and_spreads\n",
      "amrutabhate18\n",
      "monubajwal\n",
      "amol.aggarwal\n",
      "ganesh_dodave\n",
      "uditsingla\n",
      "do_bhookemusafir\n",
      "ramneat\n",
      "falguni_5495\n",
      "yavnikabhardwaj\n",
      "aked9ohtman\n",
      "thechinesefactory\n",
      "pourush_parashar\n",
      "mehak_007_\n",
      "explorendia\n",
      "imchaitanyaa\n",
      "methbabe\n",
      "9jaachi\n",
      "drishtisagar\n",
      "anchitsodhi\n",
      "shubneethayer\n",
      "an.dres8320\n",
      "__sahil_kaushik__\n",
      "sameerxosam_\n",
      "thedakbungalowgetaway\n",
      "archivedeverything\n",
      "shaan_foundation\n",
      "saavii_sharmaa\n",
      "roshanvaidhy\n",
      "sood9610\n",
      "asmaorooj\n",
      "psychological_ryder\n",
      "ank7919\n",
      "hellthy_maniacs\n",
      "labh_mann\n",
      "shubham.sr4\n",
      "username_ishaan\n",
      "damien.spl.proclimbing\n",
      "sharma_jigyasa\n",
      "ruds_in_woods\n",
      "nooointernetconnection\n",
      "mfali_\n",
      "sufisoul92\n",
      "laibarizvi22\n",
      "sanya.rehmaan\n",
      "matthew.boyington.7\n",
      "sonalii_raj\n",
      "manishaaa_98\n",
      "thisisarbaz_\n",
      "shivangee_agg\n",
      "the_jatinsaini\n",
      "p.a.r.d.h.a.a.n_official\n",
      "srivastav_rishabh\n",
      "pawankukrejaa\n",
      "jayakatariaya\n",
      "tamanna_s_jain\n",
      "teejay.pvt\n",
      "samil.aggarwal\n",
      "kanikarora10\n",
      "kash__1021\n",
      "tush.tiee\n",
      "fatehgarhsahibofficial\n",
      "duggal_2301\n",
      "abhishek.11.gupta\n",
      "the_living_photographs\n",
      "harjotisthename\n",
      "_.superb._.giggle\n",
      "the.next_photographer\n",
      "ankita_sanklecha\n",
      "stallions149\n",
      "priyabasu26\n",
      "_nitishnayal29\n",
      "divyaprakash4522\n",
      "smart_wish009\n",
      "honeydahuja\n",
      "pr33tsharma\n",
      "_metanya_\n",
      "sufi_sjs\n",
      "11_pooja_bisht\n",
      "noidaconnect\n",
      "lisazacharias_\n",
      "amenamehr\n",
      "p_jain_p\n",
      "varnika._\n",
      "jyo.ti2001\n",
      "sustainable.d.g__s.t\n",
      "iam_ankurgupta\n",
      "iam_rohittt\n",
      "shruti_rajwani\n",
      "himahith_chowdary\n",
      "namanjain.in\n",
      "chaturr278\n",
      "its_js_rawat1432\n",
      "0809namrata\n",
      "onlyayushfans\n",
      "nitin_kansal06\n",
      "chhhhiiiiirrrrrruuuuuuuuuuuuuu\n",
      "hoachutichtiphuvothituyetlan\n",
      "evlease.india\n",
      "amy_blmr\n",
      "uttkarsh._\n",
      "lil_razi1992\n",
      "rhythm_saini_\n",
      "laraaa_3\n",
      "rajesh_gupta56\n",
      "udit.jain87\n",
      "zionzelosoxaxa7\n",
      "_aakritiii\n",
      "hi_nupurrrr\n",
      "yangkiez\n",
      "_devil_yadav_339\n",
      "meenal.satija\n",
      "anannya.seth\n",
      "studio_hastak\n",
      "ma.nish9220\n",
      "charan_prit127\n",
      "shubhamrajput505\n",
      "ssimran.pvtss\n",
      "sagar_sahani_\n",
      "su_js8g7\n",
      "noidagraphy\n",
      "shezairani\n",
      "aaqib.rajput\n",
      "iamsantosh.sahu\n",
      "_mallika___\n",
      "_sakshi__23_\n",
      "sagar_princ\n",
      "yoshitagrover\n",
      "rahatmanchanda\n",
      "palak_pvt02\n",
      "arav_choudhary_arav_choudhary\n",
      "prakhar__saxena\n",
      "lifecareclinic_telemedicine\n",
      "dakkudoodle\n",
      "deeksha__gandhi12\n",
      "art_traveln\n",
      "evilin_hand\n",
      "sp_ganapati\n",
      "ayushseh\n",
      "shabnammoly\n",
      "itsrxrahul\n",
      "obscure_meals\n",
      "hasniya_khanum\n",
      "lahorizeeraofficial\n",
      "itsdeepshikhagupta\n",
      "talha_w_01\n",
      "jyoti_kanodia\n",
      "lovely_bhatia\n",
      "merakisunakami\n",
      "deo.sakshi\n",
      "sunainat2107\n",
      "travelistaforever\n",
      "atatw_travel\n",
      "bhawnashah33\n",
      "tulikapriya\n",
      "salman_hera19\n",
      "neetiteotia\n",
      "raviteja_0_7\n",
      "gaur_sourav\n",
      "ashish_15033\n",
      "surbiechauhan\n",
      "_ashusingh99\n",
      "shivamkhare1\n",
      "swpnl.vrm19\n",
      "_ahens_._\n",
      "vinaykumar_goud_rajulapati\n",
      "hu.mein.ashwatthama\n",
      "neena.chhabra\n",
      "sinfulplutoo_\n",
      "anchalnirvan\n",
      "rahul_mayank47\n",
      "anju_guddi\n",
      "insta_tattoosworld\n",
      "learning_learning_ni\n",
      "misscaffeeinated\n",
      "pooja.nagar\n",
      "yeshna.nish\n",
      "lucky_official_0400\n",
      "nikhil.goyal1993\n",
      "rohitv211\n",
      "being_ankit_28\n",
      "nswtravelogue\n",
      "your_quote256\n",
      "pawan_nayak___143\n",
      "saryu498\n",
      "serenity_skin_clinic\n",
      "_alisha_yadav_00\n",
      "ilove_youuloveme\n",
      "bunnysinghjolly\n",
      "ias_paradise\n",
      "foodygirl832\n",
      "anita___sehgal\n",
      "_balayadav_\n",
      "elizabeth_kinimi\n",
      "varunrawal47\n",
      "jatinrawatofficial_2021\n",
      "shrutiii__gupta\n",
      "mulla.inam\n",
      "afraj.khan.507\n",
      "aroundaxis\n",
      "shagunkundu\n",
      "beauty._.of._.delhi\n",
      "ruatdika_j\n",
      "mr_hydra_real\n",
      "angelatyagi_15\n",
      "sayyiid16\n",
      "shubhamsharma5894\n",
      "rihankhan1241\n",
      "shayary_bank\n",
      "aditi0812\n",
      "dillmillgayyeforever\n",
      "aditi.ii_\n",
      "suja.mohan\n",
      "chaku_and_sons\n",
      "aishna_kakkar\n",
      "aneeshjain\n",
      "silent_night________\n",
      "axzane.in\n",
      "yash_khoslaa\n",
      "malik_ul_ashtar05\n",
      "_kamran.shaikh_\n",
      "simrankumar01\n",
      "shaali145\n",
      "mahaveer_evo\n",
      "the_anas_malik\n",
      "samrddhishakargaye\n",
      "mahima_hirawat08\n",
      "rahul985997\n",
      "deepika.deepsy\n",
      "indiasimplify\n",
      "tazaherikar\n",
      "pavleen_baweja\n",
      "feedtheneed_delhi\n",
      "prerna.kansl\n",
      "smilegirl78633\n",
      "loveoreo786\n",
      "designeranshikajain04\n",
      "yashdahiya8121\n",
      "harshiiii__08\n",
      "divyat_\n",
      "aaananthu_tp\n",
      "holapartycompany\n",
      "aniketjain100\n",
      "shwetajain_15\n",
      "kaushik_hitika\n",
      "tehal_maan\n",
      "s.kaur._\n",
      "noeet11\n",
      "_.tanvi02\n",
      "guri_hangover\n",
      "itstraveltime2020\n",
      "nishtha9725\n",
      "chinki_mavi\n"
     ]
    }
   ],
   "source": [
    "flag = False # flag for condition\n",
    "while True: # check condition\n",
    "    b = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'isgrP'))) # wait till element is located\n",
    "    p = driver.find_element_by_class_name('isgrP')# search for followers\n",
    "    \n",
    "    p.click() # click on follower button                                                       \n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END) # moving end of document \n",
    "    if flag == False:\n",
    "        for i in range(6):\n",
    "            driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_UP)# to remove suggestion buttuon \n",
    "            time.sleep(1) \n",
    "        flag = True  # only work for one time\n",
    "    time.sleep(1)\n",
    "    p = driver.find_element_by_class_name('isgrP')# click on page of follower\n",
    "    follower_list = driver.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li')  #follower list\n",
    "    if len(follower_list) >= 500: # cheking for only 500 follower\n",
    "        break\n",
    "\n",
    "j = 0\n",
    "sodelhi_follower = [] # list of followers\n",
    "for i in follower_list:                                                                  \n",
    "    data = BeautifulSoup(i.get_attribute('innerHTML'),'html')  # retrieving data\n",
    "    follower_list = driver.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li')# follower list\n",
    "    if len(follower_list) >= 500: # check condition            \n",
    "        sodelhi_follower.append(data.a['href'].split('/')[1])# adding name in li\n",
    "        j+=1 # incrementing\n",
    "    if j==500: # only top 500 follower\n",
    "        break\n",
    "        \n",
    "for i in sodelhi_follower:\n",
    "    print(i) # printing names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f6fc0",
   "metadata": {},
   "source": [
    "#### 6.2) Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "152fd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1565a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No one is following back !!!!\n"
     ]
    }
   ],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.clear()\n",
    "a.send_keys('foodtalkindia') # passing 'dilsefoodie'\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is dilsefoodie hence searching by class\n",
    "handle.click() # opening the profile \n",
    "time.sleep(2)\n",
    "followers_button = wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"-nal3\")]'))) #follower button search\n",
    "followers_button.click()  \n",
    "\n",
    "flag = False  # flag for condition\n",
    "while True: # condition\n",
    "    p = driver.find_element_by_class_name('isgrP') # fetching follower button\n",
    "    p.click() # clicking on it \n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END) # moving end of document \n",
    "    \n",
    "    if flag == False: # flag for condition \n",
    "        for i in range(6):\n",
    "            driver.find_element_by_tag_name('body').send_keys(Keys.PAGE_UP) # moving up of document \n",
    "            time.sleep(1)\n",
    "        flag = True # only work for one time\n",
    "    time.sleep(1)\n",
    "    \n",
    "    follower_list = driver.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li') # follower list\n",
    "    if len(follower_list) >= 500:\n",
    "        break\n",
    "        \n",
    "j = 0\n",
    "names = [] # names of users who follow back\n",
    "for i in follower_list:\n",
    "    data = BeautifulSoup(i.get_attribute('innerHTML'),'html') # retriveing data\n",
    "    names.append(data.a['href'].split('/')[1]) # appending names to list\n",
    "    j += 1 # incrementing \n",
    "    if j == 500: # list length condition\n",
    "        break\n",
    "        \n",
    "i = 0\n",
    "count = 0  # name count \n",
    "for p in follower_list:\n",
    "    data = BeautifulSoup(p.get_attribute('innerHTML'),'html') # retriveing data\n",
    "    if data.button.text==\"Following\": # only printing that follwoing that don't follow u back \n",
    "        print(names[i]) # printing names of those who follow back\n",
    "        count += 1 # incrementing count \n",
    "    i += 1 \n",
    "if count == 0: # if no one follow back\n",
    "    print(\"No one is following back !!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927212b8",
   "metadata": {},
   "source": [
    "### 7) Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5abe8",
   "metadata": {},
   "source": [
    "#### 7.1) If You have already seen the story.\n",
    "#### 7.2) Or The user has no story.\n",
    "#### 7.3) Or View the story if not yet seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e58cb412",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84c56282",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = driver.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') # search box for passing input\n",
    "a.clear()\n",
    "a.send_keys('coding.ninjas') # passing 'dilsefoodie'\n",
    "time.sleep(3) # sleep 3 sec.\n",
    "handle = driver.find_element_by_class_name('-qQT3') # first element is dilsefoodie hence searching by class\n",
    "handle.click() # opening the profile \n",
    "count = 0 # check for story \n",
    "i = 0 # for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0972983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen the story\n",
      "Already seen the Story.\n"
     ]
    }
   ],
   "source": [
    "time.sleep(2)\n",
    "while i < 2: # iterations to be done \n",
    "    try:\n",
    "        a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'h5uC0'))) # fetching story button\n",
    "        \n",
    "        # ALREADY SEEN THE STORY\n",
    "        if count == 1: # check if already seen \n",
    "            time.sleep(0.2)\n",
    "            print(\"Already seen the Story.\") \n",
    "            \n",
    "        # VIEWING THE STORY AS NOT YET SEEN \n",
    "        else:\n",
    "            a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'_2dbep')))   \n",
    "            #for story check button\n",
    "            a.click() # click on story to see \n",
    "            time.sleep(5) # general length of story is approx 10 secs\n",
    "            print(\"Seen the story\")\n",
    "            count += 1 # incrementing the count \n",
    "\n",
    "    # DONT HAVE ANY NEW STORY\n",
    "    except TimeoutException: # handling exception\n",
    "        print(\"Don't have any new Story to view.\")\n",
    "        time.sleep(2)\n",
    "    i += 1 # incrementing for looping\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
